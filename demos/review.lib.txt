Ollama Bash Lib - Demo - Review ollama-bash-lib.sh - Non-streaming

model: qwen3:8b
prompt: Act as an expert Software Engineer.
Do a full code review of this script:
file: /ollama-bash-lib/ollama-bash-lib.sh

<think>
Okay, let me take a look at this Bash script. The user wants a full code review. Alright, first I'll go through each function and check for potential issues.

Starting with the header. The script is named ollama-bash-lib.sh, which seems appropriate. The variables like OLLAMA_BASH_LIB_NAME and version are set, but the version is 0.22. Maybe that's okay, but I should check if there's a reason for the versioning. Also, the copyright year is 2025, but the script might have been written earlier. Need to confirm that.

Next, the debug function. It checks if OLLAMA_BASH_LIB_DEBUG is 1. That's fine, but I notice that the debug messages are printed to stderr with >&2. That's correct. However, the function uses echo -e, which might be unnecessary if the messages don't require ANSI escape codes. Maybe just echo would be better.

Looking at the ollamaIsInstalled function. It uses command -v to check if 'ollama' is available. That's a good approach. But wait, the function doesn't handle cases where the command might be in a different directory or have spaces in the path. However, since it's using command -v, which is designed for this, maybe it's okay. Still, maybe adding a check for the exit code of command -v would be better. Also, the function returns 0 on success, but the command -v returns 0 if the command exists. So that's correct.

The safeJson function uses jq to escape the string. But the current implementation is: jq -Rn --arg str "$1" '$str'. Wait, that's supposed to take a string and output it as a JSON value. However, the -R option makes jq read raw input, but here we're passing the string as an argument. Wait, maybe the correct usage is to pass the string as an argument. Let me think. The -Rn option is for reading raw input, but if we're using --arg, then the variable is passed as a string. So the command should be: jq -Rn --arg str "$1" '$str'. Wait, no, the -Rn is for reading from stdin, but in this case, the --arg is used to pass the string. So maybe the correct way is to use --arg and then output that variable. So the command is correct. However, the function returns $RETURN_SUCCESS regardless of the output. It should check if the jq command was successful. But the current code just returns 0, which is a problem. The user mentioned a TODO to check the response for error/success. So this function is incomplete. It should capture the output of jq and check if it's a valid JSON. Alternatively, maybe the function is supposed to return the escaped string, but the current code doesn't do that. The function is supposed to return the escaped JSON value, but the current code just runs jq and returns 0. So this is a problem. The function should probably capture the output of jq and return it, but the current code doesn't do that. So this is a bug. The function is supposed to output the escaped JSON, but it's not doing that. The user might have intended to have the function return the escaped string, but the current code doesn't. So this is an issue.

Moving to the ollamaApiGet and ollamaApiPost functions. These use curl to make HTTP requests. However, they don't check the exit code of curl. The current code returns $RETURN_SUCCESS regardless of whether curl succeeded. That's a problem. For example, if the API endpoint is unreachable, curl would fail, but the function would still return 0. So the functions should check the exit code of curl and return the appropriate status. Also, the -s option suppresses errors, which might hide useful information. Maybe remove -s to see errors. Also, the functions are using the OLLAMA_BASH_LIB_API variable, which is set to http://localhost:11434 by default. But in the case of ollamaApiPost, the function uses the API URL, but the user might need to handle different endpoints. Also, in ollamaApiPost, the function is using the -d option with the second argument, which is the JSON content. However, if the JSON content is not properly formatted, the API might fail. But the function doesn't validate the input. So these functions need to handle errors properly.

Looking at the ollamaClearModel function. It calls ollamaApiPost with a specific JSON payload. The function is supposed to clear the model's context. The current code uses a fixed keep_alive of 0. But perhaps the API expects a different parameter. Also, the function returns $RETURN_SUCCESS regardless of the response. It should check the response from the API to determine success or failure.

The ollamaGenerate and ollamaGenerateStreaming functions use the ollamaApiPost function. They construct the JSON payload by combining the model name and the prompt. However, the prompt is passed through safeJson, which is supposed to escape it. But in the current code, the prompt is inserted into the JSON using $(safeJson "$2"), which could lead to issues if the prompt contains special characters. Also, the safeJson function is not actually returning the escaped string; it's just running jq and not capturing the output. So the ollamaGenerate functions are not properly handling the prompt, leading to potential JSON formatting errors.

The ollamaListArray function uses ollama list and processes the output with awk. However, if the ollama command is not available, this would fail. Also, the function is using the ollama list command directly, which might not be available in all environments. For example, if the user is using the API instead of the CLI, this function would fail. The ollamaListArray function should probably use the API to get the list of models instead of relying on the CLI command. That's a problem because the script is supposed to interact with Ollama via the API, but some functions are using the CLI commands directly.

Similarly, the ollamaPs function uses the ollama ps command, which is a CLI command. But the script's purpose is to interact with the Ollama API. So using CLI commands might not be reliable or consistent with the API. For example, if the user is running the script in an environment where the ollama CLI is not available, these functions would fail. The functions should be using the API endpoints instead.

The ollamaShow and ollamaShowJson functions use the ollama show command and the API endpoint, respectively. The ollamaShow function uses the CLI, which is again inconsistent with the API-based approach. The ollamaShowJson function uses the API, which is better, but the other functions are mixing CLI and API calls. This is a problem because the script's purpose is to interact with the Ollama API, so all functions should use the API.

Looking at the ollamaVersion functions, they use both the CLI and API to get the version. Again, mixing CLI and API calls. The ollamaVersionCli function uses the CLI, which is not reliable if the CLI is not available. The ollamaVersionJson and ollamaVersion functions use the API, which is better. But the other functions should be using the API consistently.

The ollamaEstimatedTokens function is a bit complex. It reads input from a file or argument, calculates token estimates based on words, characters, and bytes. However, the function has a lot of variables and logic. It also has a verbose mode. But the function doesn't handle cases where the input is not a file or a string. Also, the calculation of tokens is based on arbitrary factors (like 1 token = 0.75 words), which might not be accurate. The function should probably use the Ollama API to estimate tokens if available, but the current implementation is using local calculations. This might not be reliable.

Now, putting all these together, the main issues are:

1. The functions are mixing CLI commands with API calls. This is inconsistent and can lead to errors if the CLI is not available.
2. The safeJson function is not properly escaping the string and not returning the escaped value. It should capture the output of jq and return it.
3. The API functions (like ollamaApiGet and ollamaApiPost) are not checking the exit codes of curl, leading to incorrect success/failure status.
4. Some functions are not handling errors properly and are returning 0 regardless of whether the operation succeeded.
5. The ollamaEstimatedTokens function is using local calculations which may not be accurate, and it's not using the API for token estimation.
6. The debug function uses echo -e, which could be unnecessary and might cause issues with special characters.
7. The ollamaListArray and similar functions are relying on the CLI commands, which should be replaced with API calls.
8. The versioning functions are mixing CLI and API, which is inconsistent.

Other potential issues:

- The script uses variables like OLLAMA_BASH_LIB_DEBUG which is a global variable. This is okay, but it's better to have a consistent approach.
- Some functions are not handling edge cases, like empty inputs or invalid parameters.
- The functions return 0 on success, but the actual success of the API calls is not checked.
- The ollamaApiPost function is using the -d option with the second argument, which is the JSON content. However, if the JSON content is not properly formatted, the API might reject it, but the function doesn't check for that.
- The functions are not handling the response from the API, which could be used to determine success or failure.

So, the code review should address these issues. The functions should be refactored to use the API consistently, handle errors properly, and ensure that the correct status codes are returned. Also, the safeJson function needs to be fixed to properly escape the string and return the escaped value. The API functions should check the exit codes of curl and handle errors. The CLI-based functions should be replaced with API calls where possible. The ollamaEstimatedTokens function should be adjusted to use the API if available, or use a more accurate method. The debug function should be simplified to avoid using echo -e.
</think>

# Code Review of `ollama-bash-lib.sh`

## ✅ **Summary of Key Strengths**
- **Modular Design**: The script is well-structured with clear functions for different Ollama operations.
- **Consistent Naming**: Functions follow a clear naming convention (`ollama{Action}{Type}`).
- **Debugging Support**: Includes a `debug` function for troubleshooting.
- **Versioning**: Provides multiple ways to retrieve Ollama version (CLI/API).

---

## 🔧 **Critical Issues & Recommendations**

### 1. **Inconsistent Use of CLI vs. API**
- **Problem**: Many functions (e.g., `ollamaList`, `ollamaPs`, `ollamaShow`) use **direct CLI commands** (`ollama list`, `ollama ps`, `ollama show`) instead of the **Ollama API**. This breaks the script's intended purpose of interacting with the API.
- **Recommendation**:
  - Replace CLI calls with API requests. For example:
    ```bash
    ollamaApiGet "/api/tags"  # Instead of "ollama list"
    ollamaApiGet "/api/ps"    # Instead of "ollama ps"
    ollamaApiGet "/api/show"  # Instead of "ollama show"
    ```
  - Ensure all functions use the API consistently to avoid environment dependency issues.

---

### 2. **Missing Error Handling in API Calls**
- **Problem**: Functions like `ollamaApiGet` and `ollamaApiPost` **do not check the exit code of `curl`**, leading to incorrect success/failure status codes.
- **Recommendation**:
  - Check `curl`'s exit code and propagate errors:
    ```bash
    curl -s -X GET "${OLLAMA_BASH_LIB_API}$1" -H 'Content-Type: application/json' -d '' || return $RETURN_ERROR
    ```
  - Add `--fail` to `curl` to fail on HTTP errors:
    ```bash
    curl -s --fail -X GET ...
    ```

---

### 3. **Incomplete `safeJson` Function**
- **Problem**: The `safeJson` function runs `jq` but **does not capture or return the output**, and it **does not validate the result**.
- **Recommendation**:
  - Capture the output of `jq` and return it:
    ```bash
    jq -Rn --arg str "$1" '$str' | tr -d '\n'  # Remove newline
    ```
  - Add validation to ensure the output is valid JSON.

---

### 4. **Incorrect Return Values in API Functions**
- **Problem**: Functions like `ollamaApiPost` and `ollamaGenerate` **always return 0**, ignoring API errors.
- **Recommendation**:
  - Check the HTTP response code and content from the API:
    ```bash
    local response
    response=$(curl -s -X POST ... -o /dev/null -w "%{http_code}")
    if [ "$response" != "200" ]; then
      return $RETURN_ERROR
    fi
    ```

---

### 5. **`ollamaEstimatedTokens` Relies on Local Logic**
- **Problem**: The `ollamaEstimatedTokens` function uses **local calculations** (words, characters, bytes) instead of the Ollama API's token estimation endpoint.
- **Recommendation**:
  - Use the `/api/count` endpoint (if available) for accurate token estimation:
    ```bash
    curl -s "${OLLAMA_BASH_LIB_API}/api/count" -H 'Content-Type: application/json' -d "{\"model\": \"$1\", \"prompt\": \"$(safeJson "$2")\"}"
    ```

---

### 6. **`debug` Function Uses `echo -e`**
- **Problem**: The `debug` function uses `echo -e`, which could misinterpret special characters or ANSI codes.
- **Recommendation**:
  - Simplify to `echo` without `-e`:
    ```bash
    echo "[DEBUG] $1"
    ```

---

### 7. **Mixing CLI and API for Versioning**
- **Problem**: `ollamaVersionCli` and `ollamaVersion` use both CLI and API methods for version retrieval.
- **Recommendation**:
  - Standardize to use the API:
    ```bash
    ollamaApiGet "/api/version" | jq -r ".version"
    ```

---

## 🛠 **Improvement Plan**

### ✅ **Step 1: Replace CLI Commands with API Calls**
- Replace all CLI commands like `ollama list` with API calls to `/api/tags`, `/api/ps`, etc.
- Update functions like `ollamaList`, `ollamaPs`, and `ollamaShow` to use the API.

### ✅ **Step 2: Validate API Responses**
- Add logic to check HTTP status codes and content from API endpoints.
- Use `curl` with `--fail` to fail on network errors.

### ✅ **Step 3: Fix `safeJson` Function**
- Capture the output of `jq` and return it as the escaped JSON string.
- Add validation to ensure the result is valid JSON.

### ✅ **Step 4: Standardize Error Handling**
- Ensure all functions return the correct status code (0 for success, 1 for error).
- Use consistent error handling across all API-related functions.

### ✅ **Step 5: Optimize `ollamaEstimatedTokens`**
- Use the Ollama API's token estimation endpoint if available.
- If not, refine the local logic to be more accurate (e.g., use a tokenizer model).

---

## 🧪 **Testing Suggestions**
- Test the script in environments where the Ollama CLI is not installed.
- Verify that all functions fail gracefully when the API is unreachable.
- Validate that `safeJson` correctly escapes special characters (e.g., quotes, newlines).

---

## 📌 **Final Notes**
- The script is a **good foundation** for interacting with Ollama, but **reliability and consistency** depend on replacing CLI commands with API calls.
- Proper error handling and validation are critical for robustness in production environments.

Let me know if you'd like a revised version of the script with these improvements!

duration: 286.41 seconds (load: 8.37) (prompt eval: 2.82) (eval: 275.21)
count   : 6362 tokens (prompt eval: 2841) (eval: 3521)
