Run all Ollama Bash Lib Demos, save output to .md files

Demo directory: /app/demos

Enter API Key for Turbo Mode, or Press Enter for Local mode

OLLAMA_LIB_TURBO_KEY: (0 characters)
OLLAMA_HOST: http://localhost:11434
OLLAMA_LIB_API: http://localhost:11434

Running 31 demos: ./_is_valid_json.sh ./_is_valid_model.sh ./about.sh ./help.sh ./list.sh ./messages.sh ./ollama_api_get.sh ./ollama_app_vars.sh ./ollama_chat.sh ./ollama_eval.sh ./ollama_generate.sh ./ollama_generate_json.sh ./ollama_generate_stream.sh ./ollama_generate_stream_json.sh ./ollama_model_random.sh ./ollama_tools_simple.sh ./ollama_tools_with_args.sh ./prompt.all.models.sh ./prompts.model.sh ./ps.sh ./review.funny.sh ./review.lib-and-readme.sh ./review.lib-security.sh ./review.lib.sh ./review.readme.sh ./show.sh ./test_thinking_stream.sh ./thinking.generate.sh ./thinking.generate.stream.sh ./token.estimate.sh ./version.sh

Run: ./_is_valid_json.sh > ./_is_valid_json.md 2>&1
Run: ./_is_valid_model.sh > ./_is_valid_model.md 2>&1
Run: ./about.sh > ./about.md 2>&1
Run: ./help.sh > ./help.md 2>&1
Run: ./list.sh > ./list.md 2>&1
Run: ./messages.sh > ./messages.md 2>&1
Run: ./ollama_api_get.sh > ./ollama_api_get.md 2>&1
Run: ./ollama_app_vars.sh > ./ollama_app_vars.md 2>&1
Run: ./ollama_chat.sh > ./ollama_chat.md 2>&1
Run: ./ollama_eval.sh > ./ollama_eval.md 2>&1
Run: ./ollama_generate.sh > ./ollama_generate.md 2>&1
Run: ./ollama_generate_json.sh > ./ollama_generate_json.md 2>&1
Run: ./ollama_generate_stream.sh > ./ollama_generate_stream.md 2>&1
Run: ./ollama_generate_stream_json.sh > ./ollama_generate_stream_json.md 2>&1
Run: ./ollama_model_random.sh > ./ollama_model_random.md 2>&1
Run: ./ollama_tools_simple.sh > ./ollama_tools_simple.md 2>&1
Run: ./ollama_tools_with_args.sh > ./ollama_tools_with_args.md 2>&1
Run: ./prompt.all.models.sh > ./prompt.all.models.md 2>&1
Run: ./prompts.model.sh > ./prompts.model.md 2>&1
